% -----------------------------------------------------------------------------
%                                Introduction
% -----------------------------------------------------------------------------
\newpage                                                 \chapter{Introduction}
\renewcommand{\thepage }{\arabic{page}}                    \setcounter{page}{1}

Audible interfaces provide both sighted and visually impaired users with access
to interfaces and content. These interfaces are often used when users are
driving, using personal handheld computing devices, or unable to provide the
interface full visual attention. These interfaces are able to interact with
screen based structures as well as sensual representations of our environment
~\cite{michelis2008disappearing}.

Most audible interfaces provide a text-to-speech layer that allows systems to
read the content of the interface to the reader.  There exist solutions that
modify the behavior of an interface (such as Appleâ€™s VoiceOver).  The audio that
most of these interfaces rely on is monophonic, meaning that the audio is
perceived as coming solely from one speaker.  No effort is made to spatially
place the source of audio to provide cues to the user.

The lack of adoption of audio as an interface is often attributed to a few
factors. Prior research concludes that humans base their acceptance of sound
synthesized by machines on three features: Gestures, Nuance, and Inflection.
Most modern speech synthesizers often perform poorly on these measures.
Audible interfaces that are not based purely on speech, but focus on other
kinds of sounds have experienced more promising results
~\cite{thackara2005bubble}.

When using sounds as a communication medium to interact with humans, these
factors need to be considered due to humans sensitivity to sound. As Thackara
mentioned ~\cite{thackara2005bubble}, humans mostly have no choice but to
follow an auditory pattering as long as it does not consist out of too much
sound in the sense of noise pollution. It is important to keep these points
in mind when creating an interface based primarily on sound.

Our society is driven by information. Armed with devices that are contstantly
connected, the current generation of technology has the potential to communicate
massive amounts of information, everything from weather forecasts and traffic
conditions, to neighboring attractions, restaurant schedules, store specials,
even to the location and discoveries of our friends.

Fields of research explore how to communicate constantly changing information
to interested parties at the appropriate time.  With the influx of mobile
devices that provide an always on channel, research has explored the effect
these distruptions have on a multitasking computing environment.  The goal of
much of this research has beento study how relevant and correct information can
be efficiently delivered to a user in a manner that does not distract from
their current tasks\cite{McCrickard2003509}.

While exploring the vast world of Audible Interfaces, this paper works towards
two major goals. First a review of the methodologies, processes, and terms
necessary to study audible interfaces is presented. In conjunction with this,
an argument for the benefit of a 3D Audio Interface will be presented as an
accessible solution for users with visual disabilities. A general background
of Binaural Audio and Audible Interfaces is provided in the following section.
The related work connects ideas and findings both in the fields of Human
Computer Interaction and Signal Processing to form the basis of Our Approach
in section 6. Finally, this work concludes with an overview and survey of
future work necessary for the creation of an Binaural Audio Interface.



%-----------------------------------------------------------------------------%
\section{                  Motivation                                         }

As the push for the graphical representation of information continues within
computer science, the most prevalent solution to providing the visually impaired
with a usable computing system continues to rely heavily on screen reading
solutions. Though this solution has provided tremendous benefits, many concepts
are lost in the cross sensory translation and mapping.  For example, users of
screen readers lose the concurrency afforded by having multiple graphical
windows open simultaneously, and have a hard time discerning unprompted changes
of focus.  As interface designs continue to leverage graphics, the attempt to
translate graphic interfaces into a serial auditory stream becomes polluted with
inefficiencies and downfalls.

Imagine driving to work on a typical morning. Eric Horvitz dream of an
intelligent interface has been realized, so your navigation system is checking
current road conditions relative to the location of the GPS inside of the car.
Your smartphone has resumed polling your work email address, your calendar has
been updated by a colleague, and your family is messaging you reminding you of a
prior engagement.


system that knew exactly how much or how little to say.  The system is able to
provide just the right amount of context for each task you're performing.
